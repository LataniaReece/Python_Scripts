{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertaining Estimate Classifiers \n",
    "Often, you are not only interested in which class a classifier predicts for a certain test point, but also how certain it is that this is the right class. There are two different functions in scikit-learn that can be used to obtain uncertainty estimates from classifiers: **decision_function** and **predict_proba**.Most (but not all) classifiers have at least one of them, and many classifiers have both. \n",
    "\n",
    "#### What these functions return: \n",
    "\n",
    "To summarize, predict_proba and decision_function always have shape (n_samples, n_classes)—apart from decision_function in the special binary case. In the binary case, decision_function only has one column, corresponding to the “positive” class classes_. This is mostly for historical reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthestic Two dimensional Data set with Gbm Classifier\n",
    "Positive class = red, Negative class = blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_circles \n",
    "\n",
    "\n",
    "X, y = make_circles(noise=0.25, factor=0.5, random_state=1)\n",
    "\n",
    "# we rename the classes \"blue\" and \"red\" for illustration purposes \n",
    "y_named = np.array([\"blue\", \"red\"])[y]\n",
    "\n",
    "# we can call train_test_split with arbitrarily many arrays; \n",
    "# all will be split in a consistent manner \n",
    "X_train, X_test, y_train_named, y_test_named, y_train, y_test = \\\n",
    "train_test_split(X, y_named, y, random_state=0)\n",
    "\n",
    "# build the gradient boosting model\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train_named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the binary classification case, the return value of decision_function is of shape (n_samples,), and it returns one floating-point number for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape: (25, 2)\n",
      "Decision function shape: (25,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test.shape: {}\".format(X_test.shape)) \n",
    "print(\"Decision function shape: {}\".format(  \n",
    "    gbrt.decision_function(X_test).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value encodes how strongly the model believes a data point to belong to the “positive” class, in this case class 1. Positive values indicate a preference for the positive class, and negative values indicate a preference for the “negative” (other) class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholded decision function:\n",
      "[ True False False False  True  True False  True  True  True False  True\n",
      "  True False  True False False False  True  True  True  True  True False\n",
      " False]\n",
      "Predictions:\n",
      "['red' 'blue' 'blue' 'blue' 'red' 'red' 'blue' 'red' 'red' 'red' 'blue'\n",
      " 'red' 'red' 'blue' 'red' 'blue' 'blue' 'blue' 'red' 'red' 'red' 'red'\n",
      " 'red' 'blue' 'blue']\n"
     ]
    }
   ],
   "source": [
    "print(\"Thresholded decision function:\\n{}\".format( \n",
    "    gbrt.decision_function(X_test) > 0))\n",
    "print(\"Predictions:\\n{}\".format(gbrt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, for binary classification, the “negative” class is always the first entry of the classes_ attribute, and the “positive” class is the second entry of classes_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue', 'red'], dtype='<U4')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " if you want to fully recover the output of predict, you need to make use of the classes_ attribute like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred is equal to predictions: True\n"
     ]
    }
   ],
   "source": [
    "# make the boolean True/False into 0 and 1 \n",
    "greater_zero = (gbrt.decision_function(X_test) > 0).astype(int)\n",
    "# use 0 and 1 as indices into classes_\n",
    "pred = gbrt.classes_[greater_zero] \n",
    "# pred is the same as the output of gbrt.predict \n",
    "print(\"pred is equal to predictions: {}\".format(\n",
    "    np.all(pred == gbrt.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The range of decision_function can be arbitrary, and depends on the data and the model parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision function minimum: -7.69 maximum: 4.29\n"
     ]
    }
   ],
   "source": [
    "decision_function = gbrt.decision_function(X_test) \n",
    "print(\"Decision function minimum: {:.2f} maximum: {:.2f}\".format(   \n",
    "    np.min(decision_function), np.max(decision_function)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of predict_proba is a probability for each class, and is often more easily understood than the output of decision_function. It is always of shape (n_samples, 2) for binary classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of probabilities: (25, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of probabilities: {}\".format(gbrt.predict_proba(X_test).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first entry in each row is the estimated probability of the first class, and the second entry is the estimated probability of the second class. Because it is a probability, the output of predict_proba is always between 0 and 1, and the sum of the entries for both classes is always 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities:\n",
      "[[0.01573626 0.98426374]\n",
      " [0.84575649 0.15424351]\n",
      " [0.98112869 0.01887131]\n",
      " [0.97406775 0.02593225]\n",
      " [0.01352142 0.98647858]\n",
      " [0.02504637 0.97495363]]\n"
     ]
    }
   ],
   "source": [
    "# show the first few entries of predict_proba\n",
    "print(\"Predicted probabilities:\\n{}\".format(\n",
    "    gbrt.predict_proba(X_test[:6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: A model that is more overfitted tends to make more certain predictions, even if they might be wrong. A model with less complexity usually has more uncertainty in its predictions. A model is called calibrated if the reported uncertainty actually matches how correct it is—in a calibrated model, a prediction made with 70% certainty would be correct 70% of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty in Multiclass Classification: Iris Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris() \n",
    "X_train, X_test, y_train, y_test = train_test_split(    \n",
    "    iris.data, iris.target, random_state=42)\n",
    "gbrt = GradientBoostingClassifier(learning_rate=0.01, random_state=0)\n",
    "gbrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision function shape: (38, 3)\n",
      "Decision function:\n",
      "[[-0.52931069  1.46560359 -0.50448467]\n",
      " [ 1.51154215 -0.49561142 -0.50310736]\n",
      " [-0.52379401 -0.4676268   1.51953786]\n",
      " [-0.52931069  1.46560359 -0.50448467]\n",
      " [-0.53107259  1.28190451  0.21510024]\n",
      " [ 1.51154215 -0.49561142 -0.50310736]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision function shape: {}\".format(gbrt.decision_function(X_test).shape)) \n",
    "# plot the first few entries of the decision function \n",
    "print(\"Decision function:\\n{}\".format(gbrt.decision_function(X_test)[:6, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the multiclass case, the decision_function has the shape (n_samples, n_classes) and each column provides a “certainty score” for each class, where a large score means that a class is more likely and a small score means the class is less likely. You can recover the predictions from these scores by finding the maximum entry for each data point:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argmax of decision function:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "Predictions:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Argmax of decision function:\\n{}\".format( \n",
    "    np.argmax(gbrt.decision_function(X_test), axis=1)))\n",
    "print(\"Predictions:\\n{}\".format(gbrt.predict(X_test)))\n",
    "\n",
    "#Argmax returns the position of the largest value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of predict_proba has the same shape, (n_samples, n_classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities:\n",
      "[[0.10664722 0.7840248  0.10932798]\n",
      " [0.78880668 0.10599243 0.10520089]\n",
      " [0.10231173 0.10822274 0.78946553]\n",
      " [0.10664722 0.7840248  0.10932798]\n",
      " [0.10825347 0.66344934 0.22829719]\n",
      " [0.78880668 0.10599243 0.10520089]]\n",
      "Sums: [1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# show the first few entries of predict_proba \n",
    "print(\"Predicted probabilities:\\n{}\".format(gbrt.predict_proba(X_test)[:6])) \n",
    "# show that sums across rows are one\n",
    "print(\"Sums: {}\".format(gbrt.predict_proba(X_test)[:6].sum(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again recover the predictions by computing the argmax of predict_proba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argmax of predicted probabilities:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n",
      "Predictions:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Argmax of predicted probabilities:\\n{}\".format( \n",
    "    np.argmax(gbrt.predict_proba(X_test), axis=1))) \n",
    "print(\"Predictions:\\n{}\".format(gbrt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on using argmax: \n",
    "\n",
    "You can recover the prediction when there are n_classes many columns by computing the argmax across columns. Be careful, though, if your classes are strings, or you use integers but they are not consecutive and starting from 0. If you want to compare results obtained with predict to results obtained via decision_function or predict_proba, make sure to use the classes_ attribute of the classifier to get the actual class names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique classes in training data: ['setosa' 'versicolor' 'virginica']\n",
      "predictions: ['versicolor' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa'\n",
      " 'versicolor' 'virginica' 'versicolor' 'versicolor']\n",
      "argmax of decision function: [1 0 2 1 1 0 1 2 1 1]\n",
      "argmax combined with classes_: ['versicolor' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa'\n",
      " 'versicolor' 'virginica' 'versicolor' 'versicolor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "# represent each target by its class name in the iris dataset\n",
    "named_target = iris.target_names[y_train] \n",
    "logreg.fit(X_train, named_target) \n",
    "\n",
    "print(\"unique classes in training data: {}\".format(logreg.classes_)) \n",
    "print(\"predictions: {}\".format(logreg.predict(X_test)[:10])) \n",
    "\n",
    "argmax_dec_func = np.argmax(logreg.decision_function(X_test), axis=1) \n",
    "\n",
    "print(\"argmax of decision function: {}\".format(argmax_dec_func[:10])) \n",
    "\n",
    "#using classes_ attribute of the classifier to get the actual class names:\n",
    "print(\"argmax combined with classes_: {}\".format(     \n",
    "    logreg.classes_[argmax_dec_func][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
